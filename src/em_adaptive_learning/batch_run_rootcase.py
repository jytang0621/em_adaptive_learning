"""
æ‰¹é‡è¿è¡Œ run_rootcase.py çš„è„šæœ¬
æ”¯æŒåœ¨ä¸åŒæ•°æ®é›†ä¸Šæ‰¹é‡è¿è¡Œ EM ç®—æ³•
"""
import argparse
import subprocess
import sys
import re
from pathlib import Path
from typing import List, Dict, Any
import json
from datetime import datetime

# é»˜è®¤æ•°æ®é›†é…ç½®
DEFAULT_DATASETS = {
    "realdevbench_claude4": {
        "data_path": "/data/hongsirui/opensource_em_adaptive/em_adaptive_learning/src/em_df_realdevbench_claude_4_train.xlsx",
        "test_path": "/data/hongsirui/opensource_em_adaptive/em_adaptive_learning/src/em_df_realdevbench_claude_4_test.xlsx",
        "out_dir": "/data/hongsirui/opensource_em_adaptive/em_outputs_refine_realdevbench_appevalpilot_claude4",
        "params_path": "/data/hongsirui/opensource_em_adaptive/em_outputs_refine_realdevbench_appevalpilot_claude4/em_params.json",
    },
    "webdevjudge_claude4": {
        "data_path": "/data/hongsirui/opensource_em_adaptive/em_adaptive_learning/src/em_df_webdevjudge_claude_4_train.xlsx",
        "test_path": "/data/hongsirui/opensource_em_adaptive/em_adaptive_learning/src/em_df_webdevjudge_claude_4_test.xlsx",
        "out_dir": "/data/hongsirui/opensource_em_adaptive/em_outputs_refine_webdevjudge_appevalpilot_claude4",
        "params_path": "/data/hongsirui/opensource_em_adaptive/em_outputs_refine_webdevjudge_appevalpilot_claude4/em_params.json",
    },
    "realdevbench_ui_tars": {
        "data_path": "/data/hongsirui/opensource_em_adaptive/em_adaptive_learning/src/em_df_realdevbench_ui_tars_train.xlsx",
        "test_path": "/data/hongsirui/opensource_em_adaptive/em_adaptive_learning/src/em_df_realdevbench_ui_tars_test.xlsx",
        "out_dir": "/data/hongsirui/opensource_em_adaptive/em_outputs_refine_realdevbench_ui_tars",
        "params_path": "/data/hongsirui/opensource_em_adaptive/em_outputs_refine_realdevbench_ui_tars/em_params.json",
    },
    "webdevjudge_ui_tars":{
        "data_path": "/data/hongsirui/opensource_em_adaptive/em_adaptive_learning/src/em_df_webdevjudge_ui_tars_train.xlsx",
        "test_path": "/data/hongsirui/opensource_em_adaptive/em_adaptive_learning/src/em_df_webdevjudge_ui_tars_test.xlsx",
        "out_dir": "/data/hongsirui/opensource_em_adaptive/em_outputs_refine_webdevjudge_ui_tars",
        "params_path": "/data/hongsirui/opensource_em_adaptive/em_outputs_refine_webdevjudge_ui_tars/em_params.json",
    
    },
    # "realdevbench_claude4_query":{
    #     "data_path": "/data/hongsirui/opensource_em_adaptive/em_df_realdevbench_claude_4_train_reflection_v2_group.xlsx",
    #     "test_path": "/data/hongsirui/opensource_em_adaptive/em_df_realdevbench_claude_4_test_reflection_v2_group.xlsx",
    #     "out_dir": "/data/hongsirui/opensource_em_adaptive/em_outputs_refine_realdevbench_appevalpilot_claude4_query",
    #     "params_path": "/data/hongsirui/opensource_em_adaptive/em_outputs_refine_realdevbench_appevalpilot_claude4_query/em_params.json",
    # },
}


def run_single_experiment(
    dataset_name: str,
    dataset_config: Dict[str, Any],
    val_ratio: float = 0.4,
    seed: int = 127,
    tau_agentfail: float = 1,
    tau_envfail: float = 0.65, #0.65,
    script_path: str = None,
    agent_weight: float = 0.5,
    w_gui: float = 0.8,
    w_code: float = 1.2,
    w_noresp: float = 0.3,
) -> Dict[str, Any]:
    """
    è¿è¡Œå•ä¸ªæ•°æ®é›†çš„å®éªŒ
    
    å‚æ•°:
        dataset_name: æ•°æ®é›†åç§°
        dataset_config: æ•°æ®é›†é…ç½®å­—å…¸
        val_ratio: éªŒè¯é›†æ¯”ä¾‹
        seed: éšæœºç§å­
        tau_agentfail: AgentFail é˜ˆå€¼
        tau_envfail: EnvFail é˜ˆå€¼
        script_path: run_rootcase.py çš„è·¯å¾„
    
    è¿”å›:
        åŒ…å«è¿è¡Œç»“æœçš„å­—å…¸
    """
    if script_path is None:
        script_path = Path(__file__).parent / "run_rootcase.py"
    
    script_path = Path(script_path)
    if not script_path.exists():
        raise FileNotFoundError(f"Script not found: {script_path}")
    
    # è®°å½•å¼€å§‹æ—¶é—´
    start_time = datetime.now()
    
    # æ„å»ºå‘½ä»¤
    cmd = [
        sys.executable,
        str(script_path),
        "--dataset_name", dataset_name,
        "--data_path", dataset_config["data_path"],
        "--test_path", dataset_config["test_path"],
        "--params_path", dataset_config["params_path"],
        "--out_dir", dataset_config["out_dir"],
        "--val_ratio", str(val_ratio),
        "--seed", str(seed),
        "--tau_agentfail", str(tau_agentfail),
        "--tau_envfail", str(tau_envfail),
        "--agent_weight", str(agent_weight),
        "--w_gui", str(w_gui),
        "--w_code", str(w_code),
        "--w_noresp", str(w_noresp),
    ]
    
    print(f"\n{'â•'*80}")
    print(f"  ğŸš€ Running Experiment: {dataset_name}")
    print(f"{'â•'*80}")
    print(f"  ğŸ“ Data path:     {dataset_config['data_path']}")
    print(f"  ğŸ§ª Test path:    {dataset_config['test_path']}")
    print(f"  ğŸ“¤ Output dir:    {dataset_config['out_dir']}")
    print(f"  âš™ï¸  Params path:  {dataset_config['params_path']}")
    print(f"{'â”€'*80}")
    print(f"  â±ï¸  Started at:   {start_time.strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"{'â•'*80}\n")
    
    # è¿è¡Œå‘½ä»¤å¹¶æ•è·è¾“å‡º
    em_accuracy = None
    gate_original_acc = None
    gate_corrected_acc = None
    
    try:
        # ä½¿ç”¨Popenæ¥åŒæ—¶å®æ—¶æ˜¾ç¤ºå’Œæ•è·è¾“å‡º
        process = subprocess.Popen(
            cmd,
            stdout=subprocess.PIPE,
            stderr=subprocess.STDOUT,
            text=True,
            bufsize=1,
            universal_newlines=True
        )
        
        output_lines = []
        for line in process.stdout:
            print(line, end='')  # å®æ—¶æ˜¾ç¤º
            output_lines.append(line)
            
            # è§£æEMå‡†ç¡®ç‡
            if em_accuracy is None:
                match = re.search(r'Accuracy after correction:\s*([\d.]+)', line)
                if match:
                    em_accuracy = float(match.group(1))
            
            # è§£æGate-basedå‡†ç¡®ç‡
            if gate_original_acc is None or gate_corrected_acc is None:
                match = re.search(r'Gate-based correction - Original accuracy:\s*([\d.]+),\s*Corrected accuracy:\s*([\d.]+)', line)
                if match:
                    gate_original_acc = float(match.group(1))
                    gate_corrected_acc = float(match.group(2))
        
        process.wait()
        
        if process.returncode != 0:
            raise subprocess.CalledProcessError(process.returncode, cmd)
        
        success = True
        error_msg = None
        full_output = ''.join(output_lines)
        
    except subprocess.CalledProcessError as e:
        success = False
        error_msg = str(e)
        full_output = ''
        print(f"\n{'â”€'*80}")
        print(f"  âŒ ERROR: Experiment '{dataset_name}' failed with return code {e.returncode}")
        print(f"{'â”€'*80}")
    
    end_time = datetime.now()
    duration = (end_time - start_time).total_seconds()
    
    # æ‰“å°å®Œæˆä¿¡æ¯
    status_icon = "âœ…" if success else "âŒ"
    print(f"\n{'â”€'*80}")
    print(f"  {status_icon} Experiment '{dataset_name}' {'completed' if success else 'failed'}")
    print(f"  â±ï¸  Duration: {duration:.2f}s ({duration/60:.2f} min)")
    print(f"  ğŸ• Finished at: {end_time.strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"{'â•'*80}\n")
    
    return {
        "dataset_name": dataset_name,
        "success": success,
        "duration_seconds": duration,
        "start_time": start_time.isoformat(),
        "end_time": end_time.isoformat(),
        "error": error_msg,
        "config": dataset_config,
        "em_accuracy": em_accuracy,
        "gate_original_acc": gate_original_acc,
        "gate_corrected_acc": gate_corrected_acc,
    }


def load_config_file(config_path: str) -> Dict[str, Dict[str, Any]]:
    """
    ä» JSON æ–‡ä»¶åŠ è½½æ•°æ®é›†é…ç½®
    
    å‚æ•°:
        config_path: é…ç½®æ–‡ä»¶è·¯å¾„
    
    è¿”å›:
        æ•°æ®é›†é…ç½®å­—å…¸
    """
    with open(config_path, 'r', encoding='utf-8') as f:
        config = json.load(f)
    return config


def main():
    parser = argparse.ArgumentParser(
        description="æ‰¹é‡è¿è¡Œ run_rootcase.pyï¼Œæ”¯æŒå¤šä¸ªæ•°æ®é›†"
    )
    parser.add_argument(
        "--datasets",
        type=str,
        nargs="+",
        default=list(DEFAULT_DATASETS.keys()),
        help="è¦è¿è¡Œçš„æ•°æ®é›†åç§°åˆ—è¡¨ï¼Œé»˜è®¤è¿è¡Œæ‰€æœ‰æ•°æ®é›†",
    )
    parser.add_argument(
        "--config_file",
        type=str,
        default=None,
        help="JSON é…ç½®æ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼Œè¦†ç›–é»˜è®¤é…ç½®ï¼‰",
    )
    parser.add_argument(
        "--val_ratio",
        type=float,
        default=0.5,
        help="éªŒè¯é›†æ¯”ä¾‹ï¼ˆé»˜è®¤: 0.5ï¼‰",
    )
    parser.add_argument(
        "--seed",
        type=int,
        default=127,
        help="éšæœºç§å­ï¼ˆé»˜è®¤: 127ï¼‰",
    )
    parser.add_argument(
        "--tau_agentfail",
        type=float,
        default=0.75,
        help="AgentFail é˜ˆå€¼ï¼ˆé»˜è®¤: 0.75ï¼‰",
    )
    parser.add_argument(
        "--tau_envfail",
        type=float,
        default=0.75,
        help="EnvFail é˜ˆå€¼ï¼ˆé»˜è®¤: 0.75ï¼‰",
    )
    parser.add_argument(
        "--script_path",
        type=str,
        default=None,
        help="run_rootcase.py çš„è·¯å¾„ï¼ˆé»˜è®¤: åŒç›®å½•ä¸‹çš„ run_rootcase.pyï¼‰",
    )
    parser.add_argument(
        "--output_summary",
        type=str,
        default=None,
        help="ä¿å­˜è¿è¡Œæ‘˜è¦çš„ JSON æ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼‰",
    )
    parser.add_argument(
        "--stop_on_error",
        action="store_true",
        help="é‡åˆ°é”™è¯¯æ—¶åœæ­¢ï¼ˆé»˜è®¤: ç»§ç»­è¿è¡Œä¸‹ä¸€ä¸ªæ•°æ®é›†ï¼‰",
    )
    
    args = parser.parse_args()
    
    # åŠ è½½é…ç½®
    if args.config_file:
        datasets_config = load_config_file(args.config_file)
    else:
        datasets_config = DEFAULT_DATASETS
    
    # éªŒè¯æ•°æ®é›†åç§°
    invalid_datasets = [d for d in args.datasets if d not in datasets_config]
    if invalid_datasets:
        print(f"ERROR: Invalid dataset names: {invalid_datasets}")
        print(f"Available datasets: {list(datasets_config.keys())}")
        sys.exit(1)
    
    # è¿è¡Œå®éªŒ
    results = []
    total_start = datetime.now()
    
    print(f"\n{'â–ˆ'*80}")
    print(f"  ğŸ“Š BATCH RUN CONFIGURATION")
    print(f"{'â–ˆ'*80}")
    print(f"  ğŸ“¦ Total datasets:  {len(args.datasets)}")
    print(f"  ğŸ“‹ Datasets:        {', '.join(args.datasets)}")
    print(f"  ğŸ”¢ Val ratio:       {args.val_ratio}")
    print(f"  ğŸ² Seed:            {args.seed}")
    print(f"  âš–ï¸  Tau agentfail:   {args.tau_agentfail}")
    print(f"  âš–ï¸  Tau envfail:     {args.tau_envfail}")
    print(f"  ğŸ• Start time:      {total_start.strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"{'â–ˆ'*80}\n")
    
    for i, dataset_name in enumerate(args.datasets, 1):
        progress = f"[{i}/{len(args.datasets)}]"
        print(f"\n{'â”€'*80}")
        print(f"  {progress} Processing: {dataset_name}")
        print(f"{'â”€'*80}")
        
        dataset_config = datasets_config[dataset_name]
        
        # æ£€æŸ¥æ•°æ®æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        data_path = Path(dataset_config["data_path"])
        if not data_path.exists():
            print(f"  âš ï¸  WARNING: Data file not found: {data_path}")
            if args.stop_on_error:
                print(f"  ğŸ›‘ Stopping due to --stop_on_error flag")
                sys.exit(1)
            continue
        
        result = run_single_experiment(
            dataset_name=dataset_name,
            dataset_config=dataset_config,
            val_ratio=args.val_ratio,
            seed=args.seed,
            tau_agentfail=args.tau_agentfail,
            tau_envfail=args.tau_envfail,
            script_path=args.script_path,
        )
        
        results.append(result)
        
        if not result["success"] and args.stop_on_error:
            print(f"\n  ğŸ›‘ Stopping due to error in '{dataset_name}'")
            break
    
    total_end = datetime.now()
    total_duration = (total_end - total_start).total_seconds()
    
    # æ‰“å°æ‘˜è¦
    success_count = sum(1 for r in results if r["success"])
    failed_count = len(results) - success_count
    
    print(f"\n{'â–ˆ'*80}")
    print(f"  ğŸ“Š BATCH RUN SUMMARY")
    print(f"{'â–ˆ'*80}")
    print(f"  â±ï¸  Total duration:  {total_duration:.2f}s ({total_duration/60:.2f} min)")
    print(f"  ğŸ• Start time:       {total_start.strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"  ğŸ• End time:         {total_end.strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"{'â”€'*80}")
    print(f"  âœ… Success:          {success_count}/{len(results)}")
    print(f"  âŒ Failed:           {failed_count}/{len(results)}")
    print(f"{'â”€'*80}")
    print(f"\n  ğŸ“‹ Detailed Results:")
    print(f"  {'â”€'*130}")
    print(f"  {'Status':<12} {'Dataset':<26} {'Duration':<10} {'Original':<10} {'EM Acc':<10} {'EM+Gate Acc':<12} {'Notes'}")
    print(f"  {'â”€'*130}")
    
    for result in results:
        status_icon = "âœ…" if result["success"] else "âŒ"
        status_text = "SUCCESS" if result["success"] else "FAILED"
        duration_str = f"{result['duration_seconds']:.2f}s"
        
        # æ ¼å¼åŒ–å‡†ç¡®ç‡
        original_acc_str = f"{result.get('gate_original_acc', 0):.4f}" if result.get('gate_original_acc') is not None else "N/A"
        em_acc_str = f"{result.get('em_accuracy', 0):.4f}" if result.get('em_accuracy') is not None else "N/A"
        gate_acc_str = f"{result.get('gate_corrected_acc', 0):.4f}" if result.get('gate_corrected_acc') is not None else "N/A"
        
        notes = "ERROR" if not result["success"] else "OK"
        
        # æ ¼å¼åŒ–æ•°æ®é›†åç§°ï¼Œå¦‚æœå¤ªé•¿åˆ™æˆªæ–­
        dataset_name = result['dataset_name']
        if len(dataset_name) > 24:
            dataset_name = dataset_name[:21] + "..."
        
        print(f"  {status_icon} {status_text:<8} {dataset_name:<26} {duration_str:<10} {original_acc_str:<10} {em_acc_str:<10} {gate_acc_str:<12} {notes}")
        if result["error"]:
            error_msg = result['error'][:75] if len(result['error']) > 75 else result['error']
            print(f"           â””â”€ Error: {error_msg}")
    
    print(f"  {'â”€'*130}")
    print(f"{'â–ˆ'*80}\n")
    
    # ä¿å­˜æ‘˜è¦
    if args.output_summary:
        summary = {
            "total_duration_seconds": total_duration,
            "start_time": total_start.isoformat(),
            "end_time": total_end.isoformat(),
            "config": {
                "val_ratio": args.val_ratio,
                "seed": args.seed,
                "tau_agentfail": args.tau_agentfail,
                "tau_envfail": args.tau_envfail,
            },
            "results": results,
        }
        
        output_path = Path(args.output_summary)
        output_path.parent.mkdir(parents=True, exist_ok=True)
        
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(summary, f, indent=2, ensure_ascii=False)
        
        print(f"Summary saved to: {output_path}")
    
    # å¦‚æœæœ‰å¤±è´¥çš„å®éªŒï¼Œè¿”å›éé›¶é€€å‡ºç 
    if failed_count > 0:
        sys.exit(1)


if __name__ == "__main__":
    main()

